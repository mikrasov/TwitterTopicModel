{
 "metadata": {
  "name": "",
  "signature": "sha256:8c5b71d5ff8b7d349b37cfd0c20a769337d2e5664de76aeab539a1e073423b9e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "from nltk.stem.porter import *\n",
      "from nltk.corpus import words\n",
      "from nltk.corpus import stopwords\n",
      "import numpy as np\n",
      "import lda"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def aggregate_tweets(filename, l = 91400):\n",
      "    stemmer = PorterStemmer()\n",
      "    tweets = defaultdict(lambda : defaultdict(int))\n",
      "    vocab = set()\n",
      "    for i, line in enumerate(open(filename)):\n",
      "        if i < l:\n",
      "            for word in line.split()[1:]:\n",
      "                w = word.lower().strip('\\'\\\".,:!?#@')\n",
      "                if w not in stopwords.words('english'): \n",
      "                    if w in words.words(): #if not unicode, will assume not equal. \n",
      "                        vocab.add(stemmer.stem(w))\n",
      "                        tweets[line.split()[0]][stemmer.stem(w)]+=1\n",
      "    return tweets, list(vocab)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def individual_tweets(filename, l = 91400):\n",
      "    tweets = []\n",
      "    stemmer = PorterStemmer()\n",
      "    vocab = set()\n",
      "    users = []\n",
      "    for i,line in enumerate(open(filename)):\n",
      "        if i < l:\n",
      "            w = [word.lower() for word in line.split()[1:]]\n",
      "            w = [word.strip('\\'\\\".,:!?@#') for word in w if word.strip('\\'\\\".,:!?@#') not in stopwords.words('english')]\n",
      "            w = [stemmer.stem(word) for word in w if word in words.words()]\n",
      "            tweets.append(w)\n",
      "            vocab.update(set(word for word in w))\n",
      "            users.append(line.split()[0])\n",
      "    return tweets, list(vocab), users"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def row_to_user_aggregate(tweets):\n",
      "    return list(tweets)\n",
      "\n",
      "def row_to_user_solo(topic_user_solo, users):\n",
      "    user_index = list(set(users))\n",
      "    return user_index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_matrix_aggregated(vocab, tweets):\n",
      "    X = np.zeros((len(tweets), len(vocab)))\n",
      "    for i,user in enumerate(tweets):\n",
      "        for word in tweets[user]:\n",
      "            X[i][vocab.index(word)] = tweets[user][word]\n",
      "    return X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_matrix_solo(vocab, tweets):\n",
      "    X = np.zeros((len(tweets), len(vocab)))\n",
      "    for i,review in enumerate(tweets):\n",
      "        for word in review:\n",
      "            X[i][vocab.index(word)] += 1\n",
      "    return X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweets, vocab = aggregate_tweets('tweet_samples.txt',500)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweets_solo,vocab_solo, users = individual_tweets('tweet_samples.txt',500)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:10: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = make_matrix_aggregated(vocab,tweets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_solo= make_matrix_solo(vocab_solo, tweets_solo)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_lda(n,m, vocab,X):\n",
      "    model = lda.LDA(n)\n",
      "    model.fit(X)\n",
      "    topic_word = model.topic_word_\n",
      "    n_top_words = m\n",
      "    #for i, topic_dist in enumerate(topic_word):\n",
      "     #   topic_words = np.array(vocab)[np.argsort(topic_dist)][:-n_top_words:-1]\n",
      "     #   print('Topic {}: {}'.format(i, ', '.join(topic_words)))\n",
      "    return model.doc_topic_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def consolidate(topic_tweet, users,m):\n",
      "    user_index = list(set(users))\n",
      "    topic_user = [[0]*m]*len(user_index)\n",
      "    for i,dist in enumerate(topic_tweet):\n",
      "        topic_user[user_index.index(users[i])]+= dist\n",
      "    return topic_user"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topic_tweet = run_lda(10,10,vocab_solo,X_solo)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:lda:all zero row in document-term matrix found\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topic_user = run_lda(10,10,vocab,X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topic_user_solo = consolidate(topic_tweet,users,10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}